{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e02b3be-01b7-400c-bb1a-f2691b39389a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_paths = ['trainImages.zip', 'validationImages.zip']\n",
    "\n",
    "for path in zip_file_paths:\n",
    "    name = str(path)\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(f'unzipped/{name.split(\".\")[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd4e72-2f38-4d33-8f02-93f6e201b8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_validation = pd.read_csv('')\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e942442-ba98-4940-91db-d8466684fda6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc3d29-b1c7-41c4-83af-adbab93efb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5849b80-3f6c-49e7-bbaf-06b582b9f40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9299b1-9a0c-49bd-8846-56ef5fc93737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path_validation = \"\"\n",
    "data_path_train = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602fb08e-c4f6-4485-9d25-fbe3dad221f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "counter = 0\n",
    "\n",
    "img_paths = data_path_train\n",
    "folder = glob.glob(img_paths)\n",
    "\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf941a-394f-42aa-9a10-6579f55680cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "counter = 0\n",
    "\n",
    "img_paths = data_path_validation\n",
    "folder = glob.glob(img_paths)\n",
    "\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb86479-e854-4dc3-a25c-df8eeb493944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get image ids:\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "train_list_ids = []\n",
    "validation_list_ids = []\n",
    "\n",
    "def get_ids(split, print_this, to_append_list):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    if split == data_path_train:\n",
    "        start,end = 26,42\n",
    "    elif split == data_path_validation:\n",
    "        start,end = 31,47\n",
    "    else:\n",
    "        raise Exception(\"Invalid Parameter\")\n",
    "    folder = split\n",
    "    img_paths = glob.glob(folder)\n",
    "    img_ids = to_append_list\n",
    "    \n",
    "    for i in img_paths:\n",
    "        id = i[start:end]\n",
    "        img_ids.append(id)\n",
    "    print(len(img_ids))\n",
    "    print(print_this)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ac9e5-0e6a-4421-8681-7204f5974a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_ids(data_path_train, \"I finished the task\", train_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550335a-4585-49a9-86e7-990893ebd359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_list_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923d381-6698-4ecd-8022-a8b0c6d58396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_ids(data_path_validation, \"I finished the task\", validation_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e731a3-49e1-415d-81e4-9e46572fdada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_list_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa84de0-5208-46e9-a83e-c31fb485cb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_classes_df = pd.read_csv(\"\",names = ['className','Object'])\n",
    "validation_classes_df = pd.read_csv(\"\",names = ['className','Object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177f074-a306-45ad-9285-8d4a0af885eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_identifer = train_classes_df[train_classes_df['Object'] == 'Plastic bag']\n",
    "validation_identifer = validation_classes_df[validation_classes_df['Object'] == 'Plastic bag']\n",
    "\n",
    "print(train_identifer)\n",
    "print('------------')\n",
    "print(validation_identifer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f0cab3f-f761-4174-b322-b1d2e8227585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_row_from_df(split):\n",
    "    dataframe = \"\"\n",
    "    \n",
    "    if split == \"train\":\n",
    "        dataframe,ids_to_check = df_train, train_list_ids#517\n",
    "    elif split == \"validation\":\n",
    "        dataframe,ids_to_check = df_validation, validation_list_ids#9\n",
    "    else:\n",
    "        raise Exception(\"Invalid parameter, must be either train or validation\")\n",
    "    \n",
    "    img_ids_len = len(ids_to_check)\n",
    "    rand = random.randint(0,img_ids_len-1)\n",
    "    id = ids_to_check[rand]\n",
    "    print(id)\n",
    "    r = dataframe.loc[(dataframe.ImageID == id) & (dataframe.LabelName == '/m/05gqfk')]\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364afb7e-61b5-4ddc-8ea0-936e32c7abb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_row_from_df(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fd2ef-6fa7-4bb6-93df-f418c46dacaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "validation_images_path = \"\"#9\n",
    "train_images_path = \"\"#517\n",
    "\n",
    "\n",
    "def visualize_random_image(split):\n",
    "    split_path = train_images_path if split == 'train' else validation_images_path if split == 'validation' else 0\n",
    "    if split_path == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    images_folder = split_path\n",
    "    images_paths = glob.glob(images_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    random_int = random.randint(0,num_of_images -1)\n",
    "    random_image = images_paths[random_int]\n",
    "    img = mpimg.imread(random_image)\n",
    "    \n",
    "    #create the figure and axes\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "  \n",
    "        \n",
    "        \n",
    "    \n",
    "visualize_random_image(\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd69cd-8af8-4741-8134-d84f9c78a530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "validation_images_path = \"\"#9\n",
    "train_images_path = \"\"#517\n",
    "                      \n",
    "def visualize_many(from_num, to_num, dataset):\n",
    "    dataset_path = train_images_path if dataset == 'train' else validation_images_path if dataset == 'validation' else 0\n",
    "    if dataset_path == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    images_paths = glob.glob(dataset_path)\n",
    "    \n",
    "    index_counter = 1\n",
    "    for i in range(from_num, to_num):\n",
    "        counter = i\n",
    "        image = images_paths[counter]\n",
    "        img = mpimg.imread(image)\n",
    "        fig.add_subplot(rows, columns, index_counter)\n",
    "        plt.imshow(img)\n",
    "        index_counter +=1\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "visualize_many(0,9,\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed98eed-25cb-4a37-9e1e-df3815b6d0de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_validation.loc[(df_validation['ImageID'] == '4e24222b68123ef3') & (df_validation.LabelName == '/m/05gqfk')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a460a-e8c4-4b9d-af74-6de7bbc00c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Theory Lesson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "print(image_width, image_height) # 768 1024\n",
    "\n",
    "\n",
    "#xmin = 0.377083\n",
    "#xmax = 0.745833\n",
    "#ymin = 0.778125\n",
    "#ymax = 0.96875\n",
    "\n",
    "#new coordinates\n",
    "\n",
    "xmin = 0.377083 * image_width\n",
    "xmax = 0.745833 * image_width\n",
    "ymin = 0.778125 * image_height\n",
    "ymax = 0.96875 * image_height\n",
    "\n",
    "#xmin = 289.599\n",
    "#xmax = 572. 7997\n",
    "#ymin = 796.8\n",
    "#ymax = 992.0\n",
    "\n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin,ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "\n",
    "\n",
    "ax.add_patch(rect)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d98396-b256-41fe-b0f5-88efaccd983f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "validation_images_path = \"\"#9\n",
    "train_images_path = \"\"#517\n",
    "\n",
    "\n",
    "def visualize_bb(dataset):\n",
    "    images_path = train_images_path if dataset == 'train' else validation_images_path if dataset == 'validation' else 0\n",
    "    if dataset == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        start, end, df, split = 26, 42, df_train, \"trainImages\"\n",
    "    elif dataset == 'validation':\n",
    "        start, end, df, split = 31, 47, df_validation, \"validationImages\"\n",
    "    else:\n",
    "        raise Exception(\"Invalid parameter\")\n",
    "    \n",
    "    image_folder = images_path\n",
    "    images_paths = glob.glob(image_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    random_int = random.randint(0, num_of_images -1)\n",
    "    random_image = images_paths[random_int]\n",
    "    #print(random_image)\n",
    "    img = Image.open(random_image)\n",
    "    id_of_image = random_image[start:end]\n",
    "    \n",
    "    df_rows = df.loc[(df.ImageID == id_of_image) & (df.LabelName == '/m/05gqfk')]\n",
    "    \n",
    "    image_width, image_height = img.size\n",
    "    \n",
    "    fig ,ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    \n",
    "    for index, row in df_rows.iterrows():\n",
    "        print(row['XMin'], row['XMax'], row['YMin'], row['YMax'])\n",
    "        \n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "        \n",
    "        new_xmin = xmin * image_width\n",
    "        new_xmax = xmax * image_width\n",
    "        new_ymin = ymin * image_height\n",
    "        new_ymax = ymax * image_height\n",
    "        print(new_xmin,new_xmax,new_ymin,new_ymax)\n",
    "        \n",
    "        \n",
    "        width = new_xmax - new_xmin\n",
    "        height = new_ymax - new_ymin\n",
    "        \n",
    "        rect = patches.Rectangle((new_xmin,new_ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    \n",
    "visualize_bb(\"train\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc7c92-be57-44f1-b2f5-1fab7717218a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175d24fa-6401-4417-9af1-0b0e5b4810ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df_for_train,df_for_validation):\n",
    "    df_train_cleansed = df_train[df_train['LabelName'].str.contains('/m/05gqfk')]\n",
    "    df_validation_cleansed = df_validation[df_validation['LabelName'].str.contains('/m/05gqfk')]\n",
    "    \n",
    "    return df_train_cleansed, df_validation_cleansed\n",
    "\n",
    "df_train_cleansed, df_validation_cleansed = clean_dataframe(df_train, df_validation)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77bf6e-c3aa-404f-9dfb-b31edb9ad23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_train_cleansed)\n",
    "\n",
    "#We have 517 train images, but some of those images have multiple bb, and the 986 is the number\n",
    "#of rows we have in our new df_train_cleansed, and each row represents one bbounding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68e820-7bac-4d76-873e-e189d4b44584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "986/517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758c28d-0f57-4939-83a9-114cdef57b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_validation_cleansed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4c13d-d4f3-4637-a0e5-c6073a9db9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_validation_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b0e39-f7f2-4dc0-9fcd-7d6d2c3f2435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8542f7-b7ab-41a4-88b1-e742d42d430a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(df_train_cleansed, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119d249-8278-414d-8413-0830e7d90497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d535161-1076-4b05-bded-eefa86218b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "848bcfd5-806c-4ad4-9b40-f26f1b720ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "788 + 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c78f42-2472-4ba3-8e0b-96fdbc5e8f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "path = \"\"\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85449eb8-5b50-471f-879e-822d34c31f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecb8685-5aba-4042-b7d1-2e30dc16ec7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = test[\"ImageID\"].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4a8b1-34be-4c29-86c9-8b076b0429de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57c7f07-d86e-42d8-b977-9ec131585e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids = train[\"ImageID\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311874e4-97f9-42ae-b9e5-fa1fe2ba5a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3007526-0743-4360-ab66-461fbb4f2966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "to_loop = ''\n",
    "folder = glob.glob(to_loop)\n",
    "\n",
    "new_path = ''\n",
    "\n",
    "for path in folder:\n",
    "    id = path[26:42]\n",
    "    if ((id in test_ids)and (id in train_ids)):\n",
    "        shutil.copy(path, f\"{new_path}/{id}.jpg\")\n",
    "    elif ((id in test_ids) and (id not in train_ids)):\n",
    "        shutil.move(path, f\"{new_path}/{id}.jpg\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c459a-bf1f-4329-8694-f27e4bbc5cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_test = ''\n",
    "\n",
    "folder = glob.glob(path_to_test)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in folder:\n",
    "    counter +=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710ca4a-5820-46b0-b7fe-34c3880570ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_train = ''\n",
    "\n",
    "folder = glob.glob(path_to_train)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in folder:\n",
    "    counter +=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb3b9dd6-bec2-4bc0-8fd9-83ff11ba2930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#orignally we had 517 images, but because some of them are needed in both the train and test we now\n",
    "#have a total of 449 + 162 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb12618-7d87-42c8-9023-6e9a398a43dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "449 + 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931cc03f-96a9-45bd-9f99-40879c24bf61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "611 - 517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bcebe74-412c-4f37-b29f-07d6b84098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_image_ids = []\n",
    "                                        \n",
    "test_folder = glob.glob('')\n",
    "\n",
    "for i in test_folder:\n",
    "    id = i[25:41]\n",
    "    test_image_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51471fe5-c539-4189-af6c-0a8520601e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe2ba9f1-2461-4efc-9a2c-9058c267cf3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_image_ids = []\n",
    "                                        \n",
    "train_folder = glob.glob('')\n",
    "\n",
    "for i in train_folder:\n",
    "    id = i[26:42]\n",
    "    train_image_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a6354-c734-4f27-b47c-206d63ef4a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31665445-d3b7-4365-9713-67b75dcdb134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_ids = train['ImageID'].values.tolist()\n",
    "test_df_ids = test['ImageID'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2292ef-5c1b-4c10-8c91-19ef3b48a59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d391d4-b6ae-4d11-bb9c-478e6b752383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b5cf5-8b34-4f67-b192-1143ef554e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_both = set(train_df_ids).intersection(train_image_ids)\n",
    "len(train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b234ea-0931-4a6c-bd89-abb2f6912d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_both = set(test_df_ids).intersection(test_image_ids)\n",
    "len(test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d74375-1339-477b-aff6-fe22c03b7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 222 2 5 0.000 0.4 0.3 0.9 0.44  path/to/image11.jpg\n",
    "# 222 2 5 0.000 0.5 0.2 0.33 0.8 path/to/image11.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c09828-bca9-4f11-acf9-7dcfc227aecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#index header_column label_width className xmin ymin xmax ymax path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33ac8f7-36a4-4f25-8134-89063d0a2a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train.copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60c40f-5311-40d0-aa33-b48628e5922f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.rename(columns = {\"LabelName\": \"className\"}, inplace = True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f4ee6-78e5-4a5c-bdee-769d326980da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.rename(columns = {\"LabelName\": \"className\"}, inplace = True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf1f47-44a3-4add-b327-12f554a54c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_df))#788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86c287-08e2-428b-8d8c-3410705302ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(test_df))# 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c311dd18-e82d-4cc9-a9c7-d6a20ecaeca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"header_cols\"] = 2\n",
    "train_df[\"label_width\"] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f262ad-74a0-44da-9388-8660a8834d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ecedcd-aa93-43b8-b859-44eee24b662b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[\"header_cols\"] = 2\n",
    "test_df[\"label_width\"] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c092b7-621c-49bb-b0dd-ac051a775f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71f274e-84e2-4448-aa5c-076d41a36f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"ImagePath\"] = \"001.Plastic_bag/images/train/\"+train_df['ImageID']+ '.jpg'\n",
    "test_df[\"ImagePath\"] = \"001.Plastic_bag/images/test/\"+test_df['ImageID']+ '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c034af-24d2-486c-bfaf-a575b4107bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fd08f-3b20-4506-91dc-3f48be7d8960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a898bf4-a649-41ce-b0d9-88af457fe0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[['header_cols', 'label_width', 'className', 'XMin', 'YMin', 'XMax', 'YMax', 'ImagePath']]\n",
    "test_df = test_df[['header_cols', 'label_width', 'className', 'XMin', 'YMin', 'XMax', 'YMax', 'ImagePath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55bfb2-2d76-44e0-ba3d-4876534c635d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cae7bf47-900b-4da1-b66c-46002ab57be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "679edfdb-701b-4f24-87ab-fb0cced1356f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_train_df = train_df.copy()\n",
    "final_train_df['className'] = \"0.000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb19050-d26e-4fef-b6ed-cd3a3266780f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8f2e816-b792-4891-884e-29ff9dcba218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_test_df = test_df.copy()\n",
    "final_test_df['className'] = \"0.000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba4fda-6907-43b4-af4f-2cdc3bd4ea29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c065f54-ce5e-431a-8022-5a7ed45b18da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('','')\n",
    "shutil.move('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f79f6c-8198-4548-a9b6-93a475d2d7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('')\n",
    "count = 0\n",
    "for i in folder:\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856805dc-7e70-487f-bf60-d9155d48c71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('')\n",
    "count = 0\n",
    "for i in folder:\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa1acc-e31d-4f1a-bccf-38878d7ef4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ids = final_test_df['ImagePath'].tolist()\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82caf13-d90f-4b59-80ca-3968b8542309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = ''\n",
    "df_row = final_test_df.loc[final_test_df['ImagePath'] == image_path ]\n",
    "df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9c3fcd9-7923-429a-b0ac-fbd1ba63ca6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "\n",
    "final = []\n",
    "for id in test_ids:\n",
    "    \n",
    "    df_rows = final_test_df.loc[final_test_df['ImagePath'] == id ]\n",
    "    \n",
    "    im_path = df_rows.loc[df_rows.index[0]]['ImagePath']\n",
    "    \n",
    "    r = random.randint(0,10000000)\n",
    "    \n",
    "    length = len(df_rows)\n",
    "    count = 1\n",
    "    arr = [r, 2, 5]\n",
    "    \n",
    "    for index,row in df_rows.iterrows():\n",
    "        xmin = str(row['XMin'])\n",
    "        ymin = str(row['YMin'])\n",
    "        xmax = str(row['XMax'])\n",
    "        ymax = str(row['YMax'])\n",
    "        #className = str(row['className'])\n",
    "        \n",
    "        arr.extend([\"0.000\", xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        if count == length:\n",
    "            arr.append(im_path)\n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    final.append(arr)\n",
    "    \n",
    "    \n",
    "with open('test.lst', 'w', newline = '') as out:\n",
    "    for row in final:\n",
    "        writer = csv.writer(out, delimiter = '\\t')\n",
    "        writer.writerow(row)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42804ca5-bb19-4cff-9449-2999528a6ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_test_df[final_test_df['ImagePath'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6a3de-3645-45be-9378-c9320fac0c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Theory Lesson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "print(image_width, image_height) # 768 1024\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xmin = 0.3492 * image_width\n",
    "xmax = 0.5833 * image_width\n",
    "ymin = 0.2875 * image_height\n",
    "ymax = 0.5269 * image_height\n",
    "\n",
    "\n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin,ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "\n",
    "\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac833a0-e1b0-402f-a39a-6d9577ed6904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Theory Lesson\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('')\n",
    "im = im.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "image_width, image_height = im.size\n",
    "#print(image_width, image_height) # 768 1024\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xmin = 0.3492 * image_width\n",
    "xmax = 0.5833 * image_width\n",
    "ymin = 0.2875 * image_height\n",
    "ymax = 0.5269 * image_height\n",
    "\n",
    "xmin = (768/2) - (xmin - (768/2))\n",
    "xmax = (768/2) - (xmax - (768/2))\n",
    "\n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin,ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "\n",
    "\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eff82-1392-4f52-bfa5-e6e681a1201c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249f80e-8c3b-4ecb-841c-564d3326ed1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ec3fb-16ed-49bc-95e0-7a83662c96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "test_images_path = \"\"\n",
    "train_images_path = \"\"\n",
    "\n",
    "\n",
    "def visualize_transposed_bb(dataset):\n",
    "    images_path = train_images_path if dataset == 'train' else test_images_path if dataset == 'test' else 0\n",
    "    if dataset == 0:\n",
    "        raise Exception(\"Invalid input parameter, must be either train or validation\")\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        start, end, df, split = 53, 69, final_train_df, \"train\"\n",
    "    elif dataset == 'test':\n",
    "        start, end, df, split = 52, 68, final_test_df, \"test\"\n",
    "    else:\n",
    "        raise Exception(\"Invalid parameter\")\n",
    "    \n",
    "    image_folder = images_path\n",
    "    images_paths = glob.glob(image_folder)\n",
    "    num_of_images = len(images_paths)\n",
    "    random_int = random.randint(0, num_of_images - 1)\n",
    "    random_image = images_paths[random_int]\n",
    "    print(random_image)\n",
    "    img = Image.open(random_image)\n",
    "    img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "    id_of_image = random_image[start:end]\n",
    "    #PlasticDetection/images/001.Plastic_bag/images/test/00a76046606aa888.jpg\n",
    "    df_rows = df.loc[(df.ImagePath == f\"/{split}/{id_of_image}.jpg\") & (df.className == '0.000') ]\n",
    "    \n",
    "    image_width, image_height = img.size\n",
    "    \n",
    "    fig ,ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    \n",
    "    for index, row in df_rows.iterrows():\n",
    "        print(row['XMin'], row['XMax'], row['YMin'], row['YMax'])\n",
    "        \n",
    "        xmin = row['XMin']\n",
    "        xmax = row['XMax']\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "        \n",
    "        new_xmin = xmin * image_width\n",
    "        new_xmax = xmax * image_width\n",
    "        new_ymin = ymin * image_height\n",
    "        new_ymax = ymax * image_height\n",
    "        print(new_xmin,new_xmax,new_ymin,new_ymax)\n",
    "        \n",
    "        #flip the bb coordinates\n",
    "        xmax_flipped = (image_width/2) - (new_xmin-(image_width/2))\n",
    "        xmin_flipped = (image_width/2) - (new_xmax-(image_width/2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        width = xmax_flipped - xmin_flipped\n",
    "        height = new_ymax - new_ymin\n",
    "        \n",
    "        rect = patches.Rectangle((xmin_flipped,new_ymin), width, height, linewidth = 1, edgecolor = 'r', facecolor = 'none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    \n",
    "visualize_transposed_bb(\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b1c13-0ebc-4252-a9a8-162996e63cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(final_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "494168db-1f5e-4953-9a4a-466e6c6bc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = ''\n",
    "train_images_path = ''\n",
    "\n",
    "\n",
    "\n",
    "def augment_data(dataset):\n",
    "    images_path = train_images_path if dataset == \"train\" else test_images_path if dataset == \"test\" else 0\n",
    "    if images_path == 0:\n",
    "        raise Exception(\"Invalid Input parameter\")\n",
    "    start = 0\n",
    "    end = 0\n",
    "    if dataset == \"train\":\n",
    "        start,end,df = 29,45,final_train_df\n",
    "    elif dataset == \"test\":\n",
    "        start,end,df = 28,44,final_test_df\n",
    "    \n",
    "    \n",
    "    temp_df = pd.DataFrame(columns=[\"header_cols\",\"label_width\",\"className\",\"XMin\",\"YMin\",\"XMax\",\"YMax\",\"ImagePath\"],dtype = object)\n",
    "    counter = 0\n",
    "    for index,row in df.iterrows():\n",
    "        img_path = row[\"ImagePath\"]#image path in the df\n",
    "        id = img_path[start:end]\n",
    "        im_path = f\"/{dataset}/{id}.jpg\" #image path for the physical location of the image(full path\n",
    "        img = Image.open(im_path)\n",
    "        image_width,image_height = img.size\n",
    "        img_flip = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        img_flip.save(f\"/{dataset}/flipped_{id}.jpg\")\n",
    "        new_image_path = f\"/{dataset}/flipped_{id}.jpg\"\n",
    "        \n",
    "        xmin = row['XMin'] * image_width\n",
    "        xmax = row['XMax'] * image_width\n",
    "        ymin = row['YMin']\n",
    "        ymax = row['YMax']\n",
    "        \n",
    "        #getting the new coordinates for the flipped bounding boxes\n",
    "        new_xmin = ((image_width/2)-(xmin-(image_width/2))) / image_width\n",
    "        new_xmax = ((image_width/2)-(xmax-(image_width/2))) / image_width\n",
    "        \n",
    "        \n",
    "        temp_df.loc[counter]=[2,5,\"0.000\",new_xmin,ymin,new_xmax,ymax,new_image_path]\n",
    "        counter +=1\n",
    "    \n",
    "    df_merged = df.append(temp_df, ignore_index = True)\n",
    "\n",
    "    df_merged.to_csv(f\"{dataset}.lst\", sep = \"\\t\", float_format = \"%.4f\", header = None)\n",
    "    print(len(df))#original df\n",
    "    print(\"augmented df length below\")\n",
    "    print(len(temp_df))\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dcfec-e261-4f3d-b9ab-dcdc1841a229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(train_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5daf82-9994-4472-a491-9ee4db43f0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(test_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b39a58c-6bb3-4a86-974c-367c3bbdeb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(final_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe040d-a4e6-4d0b-b346-3d83f048144c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(final_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6fd5a-1a10-4d40-9d26-245293afc23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c0b6ed-275e-4ec5-ac15-12b073f92522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(test_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439dd2be-86fe-4373-8c2e-d83f9c863941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "162 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce863b-2179-4b53-b466-dac76147b903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c273b-9c48-45a8-a672-9fd882030f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = glob.glob(train_images_path)\n",
    "counter = 0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a944b-f757-4eae-9a60-5160bdbcbe28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "449*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc282c9-aed4-420b-9f84-1a292cf2b193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im=Image.open('')\n",
    "w,h=im.size\n",
    "\n",
    "#137\t2\t5\t0.000\t0.0569\t0.4894\t0.3169\t0.7887\t001.Plastic_bag/images/train/221dd6f9138951a7.jpg\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xmin = 0.0569\n",
    "xmax = 0.3169\n",
    "ymin = 0.4894\n",
    "ymax = 0.7887\n",
    "\n",
    "xmin=xmin*w\n",
    "xmax=xmax*w\n",
    "ymin=ymin*h\n",
    "ymax=ymax*h\n",
    "\n",
    "\n",
    "  \n",
    "width=xmax-xmin\n",
    "height=ymax-ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "  # Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "  # Display the image\n",
    "ax.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5d94e-9aa3-49e3-b193-1a93eaf6fdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im=Image.open('')\n",
    "w,h=im.size\n",
    "#925\t2\t5\t0.000\t0.9431\t0.4894\t0.6831\t0.7887\t001.Plastic_bag/images/train/flipped_221dd6f9138951a7.jpg\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xmin = 0.9431\n",
    "xmax = 0.6831\n",
    "ymin = 0.4894\n",
    "ymax = 0.7887\n",
    "\n",
    "xmin=xmin*w\n",
    "xmax=xmax*w\n",
    "ymin=ymin*h\n",
    "ymax=ymax*h\n",
    "\n",
    "\n",
    "  \n",
    "width=xmax-xmin\n",
    "height=ymax-ymin\n",
    "\n",
    "rect = patches.Rectangle((xmin, ymin), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "  # Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "  # Display the image\n",
    "ax.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2235f88-1652-40c5-b518-2e3ba64cc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.linux_distribution()[0] == \"debian\":\n",
    "    ! apt-get update\n",
    "    ! apt-get install ffmpeg libsm6 libxext6 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f636c-f736-40ae-84e2-53ce63274824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461a6404-b6b9-4d25-b7a1-f57f5f9547dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESIZE_SIZE = 256\n",
    "BASE_DIR = \"PlasticDetection/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587449ad-5cd8-4bc2-a37f-f2faeabfba8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/im2rec.py --resize $RESIZE_SIZE --pack-label test $BASE_DIR/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b3115-50af-472a-9115-e62de1b0844c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/im2rec.py --resize $RESIZE_SIZE --pack-label train $BASE_DIR/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e981c6-a9b1-44bd-aa2f-da8337f1116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = \"\"\n",
    "prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9429e2c9-763d-4f67-bd44-2fecf66e57fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b3fe5f-f291-41da-b12c-640f00cd9f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_channel = prefix + \"/train\"\n",
    "\n",
    "sess.upload_data(path= \"train.rec\", bucket = bucket, key_prefix = train_channel)\n",
    "\n",
    "s3_train_data = \"s3://{}/{}\".format(bucket,train_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580aab4-d6bc-495d-abe3-0d3a8dfb5e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(s3_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4c0c4d-1a91-495b-a6b1-3ef0f70b8198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_channel = prefix + \"/validation\"\n",
    "\n",
    "sess.upload_data(path= \"test.rec\", bucket = bucket, key_prefix = validation_channel)\n",
    "\n",
    "s3_validation_data = \"s3://{}/{}\".format(bucket,validation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42223eeb-c93e-492f-953b-db8131effd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(s3_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933cce9-c7ef-41b7-9e31-57c851b898aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_output_location =  \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d38c7-e7cf-4d66-9c5c-6bf457f679ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    \n",
    "    region = sess.boto_region_name, framework = \"object-detection\", version = \"1\"\n",
    ")\n",
    "\n",
    "print(training_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c502e4e-9d67-44e5-b969-cf933cb0e317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "od_model = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.p3.2xlarge\",\n",
    "    volume_size = 50,\n",
    "    max_run = 360000,\n",
    "    input_mode = \"File\",\n",
    "    output_path = s3_output_location,\n",
    "    sagemaker_session = sess,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061c988-aab1-4801-b106-feaf52f02873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "folder = glob.glob('')\n",
    "counter =0\n",
    "for i in folder:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06be49-1f36-4203-8d21-a60e64958e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "898 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47aa9ef-4111-4e34-8c3c-db7477339785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(od_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f50cb70c-c75e-4d81-8f9f-a0559eea5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_hyperparameters(num_epochs, lr_steps):\n",
    "    num_classes = 1\n",
    "    num_training_samples = 898\n",
    "    \n",
    "    od_model.set_hyperparameters(\n",
    "        base_network = \"resnet-50\",\n",
    "        use_pretrained_model = 1,\n",
    "        num_classes = num_classes,\n",
    "        epochs = num_epochs,\n",
    "        lr_scheduler_step = lr_steps,\n",
    "        lr_scheduler_factor = 0.1,\n",
    "        momentum = 0.9,\n",
    "        weight_decay = 0.0005,\n",
    "        nms_threshold = 0.45,\n",
    "        image_shape = 512,\n",
    "        num_training_samples = 898 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "449452b3-9aad-461d-a3ac-b35f80d979d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_hyperparameters(100, \"50,70,80,90,95\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24de4463-20d5-4a29-ae1e-15ce5b620dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \n",
    "    \"learning_rate\": ContinuousParameter(0.001,0.1),\n",
    "    \"mini_batch_size\": CategoricalParameter([8,16]),\n",
    "    \"optimizer\": CategoricalParameter([\"sgd\",\"adam\"])\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce69a63-dd3e-4170-841e-f73c29bb9823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_jobs = 8\n",
    "max_parallel_jobs = 1\n",
    "objective_metric_name = \"validation:mAP\"\n",
    "objective_type = \"Maximize\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1a1596f-af4f-4b10-8ede-0882f850af20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator = od_model,\n",
    "                            objective_metric_name = objective_metric_name,\n",
    "                            hyperparameter_ranges = hyperparameter_ranges,\n",
    "                            objective_type = objective_type,\n",
    "                            max_jobs = max_jobs,\n",
    "                            max_parallel_jobs = max_parallel_jobs          \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cb1ceed-ed86-4e06-a341-9bb36dd37b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "            s3_train_data,\n",
    "            distribution = \"FullyReplicated\",\n",
    "            content_type = \"application/x-recordio\",\n",
    "            s3_data_type = \"S3Prefix\"\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "            s3_validation_data,\n",
    "            distribution = \"FullyReplicated\",\n",
    "            content_type = \"application/x-recordio\",\n",
    "            s3_data_type = \"S3Prefix\"\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83029a65-8c89-4807-a4b7-1a71c52c9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit(inputs = data_channels, logs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bf81bf-877f-4dd3-941b-f5e3c8fd7d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605918a2-5d55-4771-a2c8-8d98bb266bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "from sagemaker import image_uris\n",
    "\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region = sess.boto_region_name, framework = \"object-detection\", version = \"1\"\n",
    ")\n",
    "print(training_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2bb32b-4583-4e11-bcdc-544e6d2ca18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "image_uri = training_image,\n",
    "model_data = '',\n",
    "role = role    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe7d1d-3132-448d-a6c2-555e786ba2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = ''\n",
    "\n",
    "deployment = model.deploy(\n",
    "initial_instance_count = 1,\n",
    "instance_type = \"ml.m4.xlarge\",\n",
    "endpoint_name = endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16ff38b-823d-48e9-8ff8-549bfc02055d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import boto3\n",
    "runtime = boto3.client(service_name = \"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64865615-2dff-4237-9f30-9046b0931abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg#pyplot\n",
    "\n",
    "\n",
    "def visualize_detection(img_file, dets, thresh = 0.6):\n",
    "    img = mpimg.imread(img_file)\n",
    "    plt.imshow(img)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    colors = dict()\n",
    "    num_detections = 0\n",
    "    for det in dets:\n",
    "        (klass,score,x0,y0,x1,y1) = det #0\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        num_detections +=1\n",
    "        cls_id = int(klass)#1\n",
    "        if cls_id not in colors:\n",
    "            colors[cls_id] = (random.random(),random.random(),random.random()) #(0.1,0.5,0.4)\n",
    "        xmin = int(x0*width)\n",
    "        ymin = int(y0*height)\n",
    "        xmax = int(x1*width)\n",
    "        ymax = int(y1*height) \n",
    "        \n",
    "        \n",
    "        rect = plt.Rectangle(\n",
    "            (xmin,ymin),\n",
    "            xmax - xmin,\n",
    "            ymax - ymin,\n",
    "            fill = False,\n",
    "            edgecolor = colors[cls_id],\n",
    "            linewidth = 3.5\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.gca().text(\n",
    "        xmin,\n",
    "        ymin-2,\n",
    "        \"{:.3f}\".format(score),\n",
    "        bbox = dict(facecolor = colors[cls_id], alpha = 0.5),\n",
    "        fontsize = 12,\n",
    "        color = \"white\"\n",
    "        )\n",
    "    print(\"Number of detections\" + str(num_detections))\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79c142c0-ec03-4fb4-9e84-9eb7afb63a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_plastic_prediction(filename, ep, thresh = 0.3):\n",
    "    b = \"\"\n",
    "    with open(filename, \"rb\" ) as image:\n",
    "        f = image.read()\n",
    "        b = bytearray(f)\n",
    "    endpoint_response = runtime.invoke_endpoint(EndpointName = ep, ContentType = \"image/jpeg\", Body = b)\n",
    "    results = endpoint_response[\"Body\"].read()\n",
    "    detections = json.loads(results)\n",
    "    \n",
    "    \n",
    "    visualize_detection(filename, detections['prediction'], thresh)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e55c2e-b940-49fd-82af-655728e346c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plastic_prediction('InternetImages/pexels-timur-weber-9533031.jpg', endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f592a849-e7b4-4b2d-9f22-ed55bacd23cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "year = date_today[0:4]\n",
    "month = date_today[5:7]\n",
    "day = date_today[8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "560a9708-09d4-429c-bcdc-47258d490f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role, image_uris\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889b8bc-3d74-408b-b45a-d7e3e110f148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region = sess.boto_region_name, framework = \"object-detection\", version = \"1\"\n",
    ")\n",
    "\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa853660-0ead-44e6-b927-05aa9193fe65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "    image_uri = training_image,\n",
    "    model_data = '',\n",
    "    role = role\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a64865e-f391-4a7b-a062-5b9bb826e944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count = 1,\n",
    "    output_path = f'',\n",
    "    instance_type = 'ml.m4.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c52b5aa-6db3-4c0e-bc9b-d94df11dcf02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data_bucket = ''\n",
    "input_file_path = f'images/{year}/{month}/{day}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c72e0-9e77-4aca-93b1-fed0ce647b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.transform(\n",
    "    \"s3://{}/{}\".format(sample_data_bucket,input_file_path), content_type = \"image/jpeg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d559a-2e3d-4a06-bc95-c8aee64cba72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(transformer.output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad389b1-1329-4e0d-95cb-e22ad8e9dfdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "year = date_today[0:4]\n",
    "month = date_today[5:7]\n",
    "day = date_today[8:10]\n",
    "\n",
    "print(date_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbd741a6-b34a-43a1-b8ac-96bbd4b21634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "my_bucket = s3.Bucket('plastic-detection-batch-transform-2023')\n",
    "\n",
    "files = []\n",
    "\n",
    "\n",
    "for object_summary in my_bucket.objects.filter(Prefix = f'batch-output/{year}/{month}/{day}'):\n",
    "    out_file = object_summary.key[24:]\n",
    "    files.append(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876160c1-686b-4fdf-ab4c-ce13c5fb8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f974c313-8123-4c1e-a54a-0c6bf0525f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p Batch_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c1c3b-6753-446d-815d-f7b74e81dc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "\n",
    "num_detections = []\n",
    "\n",
    "thresh = 0.3\n",
    "\n",
    "for i in files:\n",
    "    file_key = f'/{year}/{month}/{day}/{i}'\n",
    "    file_name_in_sagemaker = f'Batch_test_images/{i[:-4]}'\n",
    "    output = S3Downloader.read_file(file_key)\n",
    "    detections = json.loads(output)\n",
    "    detection_results = detections['prediction']\n",
    "    img = mpimg.imread(file_name_in_sagemaker)\n",
    "    plt.imshow(img)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    colors = dict()\n",
    "    num_detections = 0\n",
    "    for det in detection_results:\n",
    "        (klass,score, x0,y0,x1,y1) = det #0\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        num_detections +=1\n",
    "        cls_id = int(klass)#1\n",
    "        if cls_id not in colors:\n",
    "            colors[cls_id] = (random.random(),random.random(),random.random()) #(0.1,0.5,0.4)\n",
    "        xmin = int(x0*width)\n",
    "        ymin = int(y0*height)\n",
    "        xmax = int(x1*width)\n",
    "        ymax = int(y1*height) \n",
    "        width = xmax-xmin\n",
    "        height = ymax-ymin\n",
    "        \n",
    "        rect = plt.Rectangle(\n",
    "            (xmin,ymin),\n",
    "            width,#width\n",
    "            height, #height\n",
    "            fill = False,\n",
    "            edgecolor = colors[cls_id],\n",
    "            linewidth = 3.5\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.gca().text(\n",
    "        xmin,\n",
    "        ymin-2,\n",
    "        \"{:.3f}\".format(score),\n",
    "        bbox = dict(facecolor = colors[cls_id], alpha = 0.5),\n",
    "        fontsize = 12,\n",
    "        color = \"white\"\n",
    "        )\n",
    "    print(\"Number of detections\" + str(num_detections))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
